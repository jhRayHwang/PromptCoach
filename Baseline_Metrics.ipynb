{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9404361-c96e-44f2-97b0-3c719538f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset\n",
    "ds = load_dataset(\"Anthropic/hh-rlhf\")[\"train\"]\n",
    "\n",
    "def extract_assistant_only(text):\n",
    "    # Split by \"Human:\" and \"Assistant:\" markers (keep markers with lookahead/lookbehind)\n",
    "    segments = re.split(r'(?=Human:|Assistant:)', text)\n",
    "    \n",
    "    assistant_responses = []\n",
    "    for seg in segments:\n",
    "        if seg.startswith(\"Assistant:\"):\n",
    "            # Remove the label and clean up whitespace\n",
    "            cleaned = seg.replace(\"Assistant:\", \"\").strip()\n",
    "            if cleaned:  # Skip empty assistant turns\n",
    "                assistant_responses.append(cleaned)\n",
    "    \n",
    "    return \"\\n\\n\".join(assistant_responses).strip()\n",
    "\n",
    "cleaned_data = [\n",
    "    {\n",
    "        \"assistant_response\": extract_assistant_only(x[\"chosen\"])\n",
    "    }\n",
    "    for x in ds\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c6fe81dd-fae5-409e-9e11-5dbd95fd27ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Metrics saved to: cleaned_response_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import textstat\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load GPT-2 model\n",
    "MODEL_NAME = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "def compute_perplexity(text: str) -> float:\n",
    "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    if enc[\"input_ids\"].size(-1) == 0:\n",
    "        return float(\"nan\")  # Handle empty input gracefully\n",
    "    with torch.no_grad():\n",
    "        loss = model(**enc, labels=enc[\"input_ids\"]).loss\n",
    "    return torch.exp(loss).item()\n",
    "\n",
    "def lexical_diversity(text: str) -> float:\n",
    "    tokens = re.findall(r\"\\w+\", text.lower())\n",
    "    return len(set(tokens)) / len(tokens) if tokens else 0.0\n",
    "\n",
    "def evaluate_cleaned_data(data: list[dict], output_csv: str = \"cleaned_response_metrics.csv\"):\n",
    "    results = []\n",
    "    for row in data:\n",
    "        resp = str(row[\"assistant_response\"]).strip()\n",
    "        if not resp:\n",
    "            continue  # Skip empty responses\n",
    "\n",
    "        metrics = {\n",
    "            \"readability\":   textstat.flesch_reading_ease(resp),\n",
    "            \"perplexity\":    compute_perplexity(resp),\n",
    "            \"lex_diversity\": lexical_diversity(resp),\n",
    "        }\n",
    "\n",
    "        results.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"✔ Metrics saved to: {output_csv}\")\n",
    "    return df\n",
    "\n",
    "metrics_df = evaluate_cleaned_data(cleaned_data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b3840f6-1419-4720-a2b7-1a203470d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"gold_standard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75367266-40d7-4ce4-be95-104eb865517b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Processing: metric_results\\gemma_anger_metrics.csv\n",
      "✔ Saved labeled file → labeled_results\\gemma_anger_metrics.csv\n",
      "\n",
      "▶ Processing: metric_results\\gemma_anxious_metrics.csv\n",
      "✔ Saved labeled file → labeled_results\\gemma_anxious_metrics.csv\n",
      "\n",
      "▶ Processing: metric_results\\gemma_gratitude_metrics.csv\n",
      "✔ Saved labeled file → labeled_results\\gemma_gratitude_metrics.csv\n",
      "\n",
      "▶ Processing: metric_results\\gemma_hopeful_metrics.csv\n",
      "✔ Saved labeled file → labeled_results\\gemma_hopeful_metrics.csv\n",
      "\n",
      "▶ Processing: metric_results\\gemma_joyful_metrics.csv\n",
      "✔ Saved labeled file → labeled_results\\gemma_joyful_metrics.csv\n",
      "\n",
      "▶ Processing: metric_results\\gemma_sad_metrics.csv\n",
      "✔ Saved labeled file → labeled_results\\gemma_sad_metrics.csv\n",
      "\n",
      "▶ Processing: metric_results\\llama_anger_metrics.csv\n",
      "✔ Saved labeled file → labeled_results\\llama_anger_metrics.csv\n",
      "\n",
      "▶ Processing: metric_results\\llama_anxious_metrics.csv\n",
      "✔ Saved labeled file → labeled_results\\llama_anxious_metrics.csv\n",
      "\n",
      "▶ Processing: metric_results\\llama_gratitude_metrics.csv\n",
      "✔ Saved labeled file → labeled_results\\llama_gratitude_metrics.csv\n",
      "\n",
      "▶ Processing: metric_results\\llama_hopeful_metrics.csv\n",
      "✔ Saved labeled file → labeled_results\\llama_hopeful_metrics.csv\n",
      "\n",
      "▶ Processing: metric_results\\llama_joyful_metrics.csv\n",
      "✔ Saved labeled file → labeled_results\\llama_joyful_metrics.csv\n",
      "\n",
      "▶ Processing: metric_results\\llama_sad_metrics.csv\n",
      "✔ Saved labeled file → labeled_results\\llama_sad_metrics.csv\n",
      "\n",
      "▶ Processing: metric_results\\original_metrics.csv\n",
      "✔ Saved labeled file → labeled_results\\original_metrics.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set your input/output directories\n",
    "input_dir = \"metric_results\"\n",
    "output_dir = \"labeled_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define a function to label the metrics\n",
    "def label_metrics(df):\n",
    "    # Drop rows with missing values in metrics (if any)\n",
    "    df = df.dropna(subset=['readability', 'lex_diversity', 'perplexity'])\n",
    "\n",
    "    # Compute thresholds\n",
    "    summary_stats = df[['readability', 'lex_diversity', 'perplexity']].quantile([0.25, 0.5, 0.75])\n",
    "    \n",
    "    read_thresh = summary_stats.loc[0.5, 'readability']        # median\n",
    "    lex_thresh  = summary_stats.loc[0.25, 'lex_diversity']     # 25th percentile\n",
    "    perp_thresh = summary_stats.loc[0.75, 'perplexity']        # 75th percentile\n",
    "\n",
    "    # Apply labeling\n",
    "    df['readability_label'] = df['readability'].apply(lambda x: 'good' if x > read_thresh else 'bad')\n",
    "    df['lex_diversity_label'] = df['lex_diversity'].apply(lambda x: 'good' if x > lex_thresh else 'bad')\n",
    "    df['perplexity_label'] = df['perplexity'].apply(lambda x: 'good' if x < perp_thresh else 'bad')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Loop through all CSVs in the input folder\n",
    "for file in os.listdir(input_dir):\n",
    "    if file.endswith(\".csv\"):\n",
    "        filepath = os.path.join(input_dir, file)\n",
    "        print(f\"▶ Processing: {filepath}\")\n",
    "\n",
    "        df = pd.read_csv(filepath)\n",
    "\n",
    "        # Add labels\n",
    "        labeled_df = label_metrics(df)\n",
    "\n",
    "        # Save to output folder\n",
    "        out_path = os.path.join(output_dir, file)\n",
    "        labeled_df.to_csv(out_path, index=False)\n",
    "        print(f\"✔ Saved labeled file → {out_path}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
